{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3c014a-efc7-43db-99ec-acdb8c7f86b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "from utils.utils import LoadDataset, RandomErasing, set_seed\n",
    "from simclr.simclr_model import SimCLR\n",
    "from byol.byol_model import BYOL\n",
    "from moco.moco_model import MoCo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d190bf3-d281-44de-b319-6c299e5347b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 2000\n",
      "Number of images loaded: 6500\n",
      "Number of images loaded: 3850\n"
     ]
    }
   ],
   "source": [
    "# Replace the path with the path to the dataset on your machine\n",
    "cat_dog_dataset =  LoadDataset(\"/home/jovyan/data/cat_dog/\", 50).load_data()\n",
    "vehicles_dataset = LoadDataset(\"/home/jovyan/data/vehicles/\", 50).load_data()\n",
    "clothing_dataset = LoadDataset(\"/home/jovyan/data/clothing/\", 50).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e85705-c844-426d-858f-e5173e7232aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_vector_machine(feature_vectors, labels, cv_folds=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Support Vector Machine classifier\n",
    "    Parameters:\n",
    "    feature_vectors: numpy array of shape (n_samples, n_features)\n",
    "    labels: numpy array of shape (n_samples,)\n",
    "    cv_folds: int, number of cross-validation folds\n",
    "    Returns:\n",
    "    accuracy_train: float, accuracy on the training set\n",
    "    accuracy_test: float, accuracy on the test set\n",
    "    cross_val_scores: numpy array of shape (cv_folds,), accuracy scores for each fold\n",
    "    \"\"\"\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(feature_vectors)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    if len(unique_labels) == 2:\n",
    "        classifier = SVC(kernel='linear', random_state=42)\n",
    "    else:\n",
    "        classifier = SVC(kernel='linear', decision_function_shape='ovr', random_state=42, break_ties=True)\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = classifier.predict(X_train)\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(classifier, features_scaled, labels, cv=cv_folds)\n",
    "    \n",
    "    return accuracy_train, accuracy_test, cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4739de4a-3342-4614-84a4-29e1f61ccb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(feature_vectors, labels, cv_folds=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Random Forest classifier\n",
    "    Parameters:\n",
    "    feature_vectors: numpy array of shape (n_samples, n_features)\n",
    "    labels: numpy array of shape (n_samples,)\n",
    "    cv_folds: int, number of cross-validation folds\n",
    "    Returns:\n",
    "    accuracy_train: float, accuracy on the training set\n",
    "    accuracy_test: float, accuracy on the test set\n",
    "    cross_val_scores: numpy array of shape (cv_folds,), accuracy scores for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(feature_vectors)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "    \n",
    "    classifier = RandomForestClassifier(random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = classifier.predict(X_train)\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(classifier, features_scaled, labels, cv=cv_folds)\n",
    "    \n",
    "    return accuracy_train, accuracy_test, cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c7f0d3-8f26-4872-9467-59e863cabb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(feature_vectors, labels, cv_folds=5):\n",
    "\n",
    "    \"\"\"K-Nearest Neighbors classifier\n",
    "    Parameters:\n",
    "    feature_vectors: numpy array of shape (n_samples, n_features)\n",
    "    labels: numpy array of shape (n_samples,)\n",
    "    cv_folds: int, number of cross-validation folds\n",
    "    Returns:\n",
    "    accuracy_train: float, accuracy on the training set\n",
    "    accuracy_test: float, accuracy on the test set\n",
    "    cross_val_scores: numpy array of shape (cv_folds,), accuracy scores for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(feature_vectors)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "    \n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = classifier.predict(X_train)\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(classifier, features_scaled, labels, cv=cv_folds)\n",
    "    \n",
    "    return accuracy_train, accuracy_test, cross_val_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bb50b4-8e71-435e-b3c1-c5551a2c7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_classifier(feature_vectors, labels, cv_folds=5):\n",
    "\n",
    "    \"\"\"\n",
    "    Neural Network classifier\n",
    "    Parameters:\n",
    "    feature_vectors: numpy array of shape (n_samples, n_features)\n",
    "    labels: numpy array of shape (n_samples,)\n",
    "    cv_folds: int, number of cross-validation folds\n",
    "    Returns:\n",
    "    accuracy_train: float, accuracy on the training set\n",
    "    accuracy_test: float, accuracy on the test set\n",
    "    cross_val_scores: numpy array of shape (cv_folds,), accuracy scores for each fold\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(feature_vectors)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', random_state=42, max_iter=1000)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = classifier.predict(X_train)\n",
    "    y_test_predict = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy_train = accuracy_score(y_train, y_train_predict)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "    \n",
    "    cross_val_scores = cross_val_score(classifier, features_scaled, labels, cv=cv_folds)\n",
    "    \n",
    "    return accuracy_train, accuracy_test, cross_val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6d749c-acd5-4204-aff3-7a2cd51589c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_feature_vectors_from_moco(model_path, data_loader):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to extract feature vectors from a pre-trained MoCo model\n",
    "    Parameters:\n",
    "    model_path: str, path to the pre-trained model\n",
    "    data_loader: torch DataLoader object\n",
    "    Returns:\n",
    "    feature_vectors: numpy array of shape (n_samples, n_features), extracted feature vectors\n",
    "    labels: numpy array of shape (n_samples,), labels for the feature vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet = torchvision.models.resnet18()\n",
    "    backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "    model = MoCo(backbone)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    feature_vectors = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, label in data_loader:\n",
    "            images = images.to(device) \n",
    "            outputs = model.backbone(images).flatten(start_dim=1)\n",
    "            feature_vectors.append(outputs.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "    feature_vectors = np.concatenate(feature_vectors)\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    return feature_vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efb4712-f2e4-4999-8a66-fbef025e3fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the pre-trained models paths different seed values, replace with your own paths\n",
    "moco_models = {\"seed 0\": [\"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_center_cropping.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_cropping.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_color_jitter.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_flipping.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_perspective.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_rotation.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_grayscale.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_gaussian_blur.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_invert.pth\", \n",
    "                          \"/home/jovyan/models/trained_models/seed_zero/moco/moco_model_random_erasing.pth\"], \n",
    "                 \n",
    "                \"seed 42\": [\"/home/jovyan/models/trained_models/seed_42/moco/moco_model_center_cropping.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_cropping.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_color_jitter.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_flipping.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_perspective.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_rotation.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_grayscale.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_gaussian_blur.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_invert.pth\", \n",
    "                            \"/home/jovyan/models/trained_models/seed_42/moco/moco_model_random_erasing.pth\"],\n",
    "                 \n",
    "                \"seed 123\": [\"/home/jovyan/models/trained_models/seed_123/moco/moco_model_center_cropping.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_cropping.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_color_jitter.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_flipping.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_perspective.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_rotation.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_grayscale.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_gaussian_blur.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_invert.pth\", \n",
    "                             \"/home/jovyan/models/trained_models/seed_123/moco/moco_model_random_erasing.pth\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fc6888-922c-4547-bc5b-a9ed49bc81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moco_svm_accuracies(models, dataset):\n",
    "\n",
    "    \"\"\"Function to extract feature vectors from pre-trained MoCo models and train SVM classifiers\n",
    "    Parameters:\n",
    "    models: dict, dictionary containing the paths to the pre-trained MoCo models\n",
    "    dataset: torch DataLoader object\n",
    "    Returns:\n",
    "    pandas DataFrame, containing the accuracies of the pre-trained models\n",
    "    \"\"\"\n",
    "    accuracies = {\n",
    "        \"seed\": [],\n",
    "        \"augmentation\": [],\n",
    "        \"accuracy_train\": [],\n",
    "        \"accuracy_test\": [],\n",
    "        \"cross_val_score\": []\n",
    "    }\n",
    "\n",
    "    for seed, model_paths in models.items():\n",
    "        for model_path in model_paths:\n",
    "            augmentation = model_path.split('/')[-1].replace('.pth', '')\n",
    "            \n",
    "            \n",
    "            features, labels = extracting_feature_vectors_from_moco(model_path, dataset)\n",
    "            acc_train, acc_test, cross_val_scores = support_vector_machine(features, labels)\n",
    "            accuracies[\"seed\"].append(seed)\n",
    "            accuracies[\"augmentation\"].append(augmentation)\n",
    "            accuracies[\"accuracy_train\"].append(acc_train)\n",
    "            accuracies[\"accuracy_test\"].append(acc_test)\n",
    "            accuracies[\"cross_val_score\"].append(cross_val_scores)\n",
    "           \n",
    "    return pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159d289c-e4d5-44d0-ba7c-64a0e1bc986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_svm_cat_dog_accuracies_df =  get_moco_svm_accuracies(moco_models, cat_dog_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_svm_cat_dog_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_svm_cat_dog_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd08f34-a563-4867-83e3-2dfee7a1f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_svm_vehicles_accuracies_df =  get_moco_svm_accuracies(moco_models, vehicles_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_svm_vehicles_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_svm_vehicles_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49c8de6-36a8-4297-ac1c-c3ac31ca3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_svm_clothes_accuracies_df =  get_moco_svm_accuracies(moco_models, clothing_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_svm_clothes_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_svm_clothes_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1ad2e6-155c-47c2-a597-95ee456c9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moco_knn_accuracies(models, dataset):\n",
    "\n",
    "    \"\"\"Function to extract feature vectors from pre-trained MoCo models and train KNN classifiers\n",
    "    Parameters:\n",
    "    models: dict, dictionary containing the paths to the pre-trained MoCo models\n",
    "    dataset: torch DataLoader object\n",
    "    Returns:\n",
    "    pandas DataFrame, containing the accuracies of the pre-trained models\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracies = {\n",
    "        \"seed\": [],\n",
    "        \"augmentation\": [],\n",
    "        \"accuracy_train\": [],\n",
    "        \"accuracy_test\": [],\n",
    "        \"cross_val_score\": []\n",
    "    }\n",
    "\n",
    "    for seed, model_paths in models.items():\n",
    "        for model_path in model_paths:\n",
    "            augmentation = model_path.split('/')[-1].replace('.pth', '')\n",
    "            \n",
    "            \n",
    "            features, labels = extracting_feature_vectors_from_moco(model_path, dataset)\n",
    "            acc_train, acc_test, cross_val_scores = k_nearest_neighbors(features, labels)\n",
    "            accuracies[\"seed\"].append(seed)\n",
    "            accuracies[\"augmentation\"].append(augmentation)\n",
    "            accuracies[\"accuracy_train\"].append(acc_train)\n",
    "            accuracies[\"accuracy_test\"].append(acc_test)\n",
    "            accuracies[\"cross_val_score\"].append(cross_val_scores)\n",
    "           \n",
    "    return pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba99d3e9-c40d-4bad-9c4d-e0196e81305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_knn_cat_dog_accuracies_df =  get_moco_knn_accuracies(moco_models, cat_dog_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_knn_cat_dog_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_knn_cat_dog_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38320664-aad0-4e61-aaae-f83489ed3c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_knn_vehicles_accuracies_df =  get_moco_knn_accuracies(moco_models, vehicles_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_knn_vehicles_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_knn_vehicles_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c63f3af-b832-483b-a43c-1c1ab98cf3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_knn_clothes_accuracies_df =  get_moco_knn_accuracies(moco_models, clothing_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_knn_clothes_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_knn_clothes_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d77d54-783e-45d7-9424-d192dea36256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moco_rf_accuracies(models, dataset):\n",
    "\n",
    "    \"\"\"Function to extract feature vectors from pre-trained MoCo models and train Random Forest classifiers\n",
    "    Parameters:\n",
    "    models: dict, dictionary containing the paths to the pre-trained MoCo models\n",
    "    dataset: torch DataLoader object\n",
    "    Returns:\n",
    "    pandas DataFrame, containing the accuracies of the pre-trained models\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracies = {\n",
    "        \"seed\": [],\n",
    "        \"augmentation\": [],\n",
    "        \"accuracy_train\": [],\n",
    "        \"accuracy_test\": [],\n",
    "        \"cross_val_score\": []\n",
    "    }\n",
    "\n",
    "    for seed, model_paths in models.items():\n",
    "        for model_path in model_paths:\n",
    "            augmentation = model_path.split('/')[-1].replace('.pth', '')\n",
    "            \n",
    "            \n",
    "            features, labels = extracting_feature_vectors_from_moco(model_path, dataset)\n",
    "            acc_train, acc_test, cross_val_scores = random_forest(features, labels)\n",
    "            accuracies[\"seed\"].append(seed)\n",
    "            accuracies[\"augmentation\"].append(augmentation)\n",
    "            accuracies[\"accuracy_train\"].append(acc_train)\n",
    "            accuracies[\"accuracy_test\"].append(acc_test)\n",
    "            accuracies[\"cross_val_score\"].append(cross_val_scores)\n",
    "           \n",
    "    return pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b70a1513-2d0f-4d27-a758-882e86153055",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_rf_cat_dog_accuracies_df =  get_moco_rf_accuracies(moco_models, cat_dog_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_rf_cat_dog_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_rf_cat_dog_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98db135b-d7d4-4e96-adb3-9f4aee97f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_rf_vehicles_accuracies_df =  get_moco_rf_accuracies(moco_models, vehicles_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_rf_vehicles_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_rf_vehicles_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c7cf474-03f6-40e7-845c-724582855897",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_rf_clothes_accuracies_df =  get_moco_rf_accuracies(moco_models, clothing_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_rf_clothes_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_rf_clothes_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72aa3fc2-4f92-4937-a111-c903242395da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moco_nn_accuracies(models, dataset):\n",
    "\n",
    "    \"\"\"Function to extract feature vectors from pre-trained MoCo models and train Neural Network classifiers\n",
    "    Parameters:\n",
    "    models: dict, dictionary containing the paths to the pre-trained MoCo models\n",
    "    dataset: torch DataLoader object\n",
    "    Returns:\n",
    "    pandas DataFrame, containing the accuracies of the pre-trained models\n",
    "    \"\"\"\n",
    "    \n",
    "    accuracies = {\n",
    "        \"seed\": [],\n",
    "        \"augmentation\": [],\n",
    "        \"accuracy_train\": [],\n",
    "        \"accuracy_test\": [],\n",
    "        \"cross_val_score\": []\n",
    "    }\n",
    "\n",
    "    for seed, model_paths in models.items():\n",
    "        for model_path in model_paths:\n",
    "            augmentation = model_path.split('/')[-1].replace('.pth', '')\n",
    "            \n",
    "\n",
    "            features, labels = extracting_feature_vectors_from_moco(model_path, dataset)\n",
    "            acc_train, acc_test, cross_val_scores = neural_network_classifier(features, labels)\n",
    "            accuracies[\"seed\"].append(seed)\n",
    "            accuracies[\"augmentation\"].append(augmentation)\n",
    "            accuracies[\"accuracy_train\"].append(acc_train)\n",
    "            accuracies[\"accuracy_test\"].append(acc_test)\n",
    "            accuracies[\"cross_val_score\"].append(cross_val_scores)\n",
    "           \n",
    "    return pd.DataFrame(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "630913b3-a6a1-4dd9-9765-63e9efcb058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_nn_cat_dog_accuracies_df =  get_moco_nn_accuracies(moco_models, cat_dog_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_nn_cat_dog_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_nn_cat_dog_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26f7ec25-e4a2-4328-b6d6-823f64376a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_nn_vehicles_accuracies_df =  get_moco_nn_accuracies(moco_models, vehicles_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_nn_vehicles_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_nn_vehicles_accuracies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abeb9a6f-83bf-42ac-922e-0fd58566a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_nn_clothes_accuracies_df =  get_moco_nn_accuracies(moco_models, clothing_dataset)\n",
    "# Replace the path with the path where you want to save the accuracies\n",
    "moco_nn_clothes_accuracies_df.to_csv(\"/home/jovyan/scripts/accuracies/moco/moco_nn_clothes_accuracies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
